name: "CIFAR100_full"

layer {
  name: "cifar"
  type: "HDF5Data"
  # the 1st top is the data itself: the name is only convention
  top: "data"

  # the 2nd top is the ground truth: the name is only convention
  # TBD: "coarse_labels" or "fine_labels"
  top: "fine_labels"
  include {
    phase: TRAIN
  }

  # the Data layer configuration
  hdf5_data_param {
    # path to the DB
    # TBD: update the content (and save to different file) if the .txt file if adding data
    source: "train.txt"

    # TBD: batch size
    batch_size: 100
  }
}
layer {
  name: "cifar"
  type: "HDF5Data"
  # the 1st top is the data itself: the name is only convention
  top: "data"

  # the 2nd top is the ground truth: the name is only convention
  # TBD: "coarse_labels" or "fine_labels"
  top: "fine_labels"
  include {
    phase: TEST
  }

  hdf5_data_param {
    # DO NOT AUGMENT THE TEST or Validation DATA.
    source: "validation.txt"
    # TBD: change source to test data ONLY with the FINAL trained network

    # TBD: batch size
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w" # added to reference later the weight at a "siamese" network 		
    lr_mult: 1
    decay_mult: 0
  }
  param {
    name: "conv1_b" # added to reference later the weight at a "siamese" network 		
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}

layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "dropp1"
  type: "Dropout"
  bottom: "pool1"
  top: "pool1"
  dropout_param {
    dropout_ratio: 0.1
  }
}


layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    name: "conv2_w" # added to reference later the weight at a "siamese" network 		
    lr_mult: 1
    decay_mult: 0
  }
  param {
    name: "conv2_b" # added to reference later the weight at a "siamese" network 		
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "dropc2"
  type: "Dropout"
  bottom: "conv2"
  top: "conv2"
  dropout_param {
    dropout_ratio: 0.2
  }
}

layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    name: "conv3_w" # added to reference later the weight at a "siamese" network 		
    lr_mult: 1
    decay_mult: 0
  }
  param {
    name: "conv3_b" # added to reference later the weight at a "siamese" network 		
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "dropconv3"
  type: "Dropout"
  bottom: "conv3"
  top: "conv3"
  dropout_param {
    dropout_ratio: 0.5
  }
}

layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1_fine"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1_fine"
  param {
    name: "ip1f_w" # added to reference later the weight at a "siamese" network
    lr_mult: 100
    decay_mult: 1
  }
  param {
    name: "ip1f_b" # added to reference later the weight at a "siamese" network
    lr_mult: 200
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {
  name: "dropip1c"
  type: "Dropout"
  bottom: "ip1_fine"
  top: "ip1_fine"
  dropout_param {
    dropout_ratio: 0.5
  }
}

layer {
  name: "ip2_fine"
  type: "InnerProduct"
  bottom: "ip1_fine"
  top: "ip2_fine"
  param {
    name: "ip2f_w" # added to reference later the weight at a "siamese" network
    lr_mult: 100
    decay_mult: 1
  }
  param {
    name: "ip2f_b" # added to reference later the weight at a "siamese" network
    lr_mult: 200
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {
  name: "dropip2c"
  type: "Dropout"
  bottom: "ip2_fine"
  top: "ip2_fine"
  dropout_param {
    dropout_ratio: 0.5
  }
}

layer {
  name: "accuracy_fine"
  type: "Accuracy"
  bottom: "ip2_fine"
  bottom: "fine_labels"
  top: "accuracy_fine"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2_fine"
  bottom: "fine_labels"
  top: "loss"
}
